//! Audio Decoder and Player
//!
//! Decode Opus audio using FFmpeg and play through cpal.
//! Optimized for low-latency streaming with jitter buffer.
//! Supports dynamic device switching and sample rate conversion.

use anyhow::{Result, Context, anyhow};
use log::{info, warn, error, debug};
use std::sync::Arc;
use std::sync::mpsc;
use std::thread;
use parking_lot::Mutex;
use std::sync::atomic::{AtomicUsize, AtomicBool, Ordering};

extern crate ffmpeg_next as ffmpeg;

use ffmpeg::codec::{decoder, context::Context as CodecContext};
use ffmpeg::Packet;

/// Audio decoder using FFmpeg for Opus
/// Non-blocking: decoded samples are sent to a channel
pub struct AudioDecoder {
    cmd_tx: mpsc::Sender<AudioCommand>,
    /// For async decoding - samples come out here
    sample_rx: Option<tokio::sync::mpsc::Receiver<Vec<i16>>>,
    sample_rate: u32,
    channels: u32,
}

enum AudioCommand {
    /// Decode audio and send result to channel
    DecodeAsync(Vec<u8>),
    Stop,
}

impl AudioDecoder {
    /// Create a new Opus audio decoder using FFmpeg
    /// Returns decoder and a receiver for decoded samples (for async operation)
    pub fn new(sample_rate: u32, channels: u32) -> Result<Self> {
        info!("Creating Opus audio decoder: {}Hz, {} channels", sample_rate, channels);

        // Initialize FFmpeg (may already be initialized by video decoder)
        let _ = ffmpeg::init();

        // Create channels for thread communication
        let (cmd_tx, cmd_rx) = mpsc::channel::<AudioCommand>();
        // Async channel for decoded samples - large buffer to prevent blocking
        let (sample_tx, sample_rx) = tokio::sync::mpsc::channel::<Vec<i16>>(512);

        // Spawn decoder thread (FFmpeg types are not Send)
        let sample_rate_clone = sample_rate;
        let channels_clone = channels;

        thread::spawn(move || {
            // Find Opus decoder
            let codec = match ffmpeg::codec::decoder::find(ffmpeg::codec::Id::OPUS) {
                Some(c) => c,
                None => {
                    error!("Opus decoder not found in FFmpeg");
                    return;
                }
            };

            let ctx = CodecContext::new_with_codec(codec);

            let mut decoder = match ctx.decoder().audio() {
                Ok(d) => d,
                Err(e) => {
                    error!("Failed to create Opus decoder: {:?}", e);
                    return;
                }
            };

            info!("Opus audio decoder initialized (async mode)");

            while let Ok(cmd) = cmd_rx.recv() {
                match cmd {
                    AudioCommand::DecodeAsync(data) => {
                        let samples = Self::decode_opus_packet(&mut decoder, &data, sample_rate_clone, channels_clone);
                        if !samples.is_empty() {
                            // Non-blocking send - drop samples if channel is full
                            let _ = sample_tx.try_send(samples);
                        }
                    }
                    AudioCommand::Stop => break,
                }
            }

            debug!("Audio decoder thread stopped");
        });

        Ok(Self {
            cmd_tx,
            sample_rx: Some(sample_rx),
            sample_rate,
            channels,
        })
    }

    /// Take the sample receiver (for passing to audio player thread)
    pub fn take_sample_receiver(&mut self) -> Option<tokio::sync::mpsc::Receiver<Vec<i16>>> {
        self.sample_rx.take()
    }

    /// Decode an Opus packet from RTP payload
    fn decode_opus_packet(
        decoder: &mut decoder::Audio,
        data: &[u8],
        target_sample_rate: u32,
        target_channels: u32,
    ) -> Vec<i16> {
        if data.is_empty() {
            return Vec::new();
        }

        // Create packet from raw Opus data
        let mut packet = Packet::new(data.len());
        if let Some(pkt_data) = packet.data_mut() {
            pkt_data.copy_from_slice(data);
        } else {
            return Vec::new();
        }

        // Send packet to decoder
        if let Err(e) = decoder.send_packet(&packet) {
            match e {
                ffmpeg::Error::Other { errno } if errno == libc::EAGAIN => {}
                _ => debug!("Audio send packet error: {:?}", e),
            }
        }

        // Receive decoded audio frame
        let mut frame = ffmpeg::frame::Audio::empty();
        match decoder.receive_frame(&mut frame) {
            Ok(_) => {
                // Convert frame to i16 samples
                let samples = Self::frame_to_samples(&frame, target_sample_rate, target_channels);
                samples
            }
            Err(ffmpeg::Error::Other { errno }) if errno == libc::EAGAIN => {
                Vec::new()
            }
            Err(e) => {
                debug!("Audio receive frame error: {:?}", e);
                Vec::new()
            }
        }
    }

    /// Convert FFmpeg audio frame to i16 samples
    fn frame_to_samples(
        frame: &ffmpeg::frame::Audio,
        _target_sample_rate: u32,
        target_channels: u32,
    ) -> Vec<i16> {
        use ffmpeg::format::Sample;

        let nb_samples = frame.samples();
        let channels = frame.channels() as usize;

        if nb_samples == 0 || channels == 0 {
            return Vec::new();
        }

        let format = frame.format();
        let mut output = Vec::with_capacity(nb_samples * target_channels as usize);

        // Handle different sample formats
        match format {
            Sample::I16(planar) => {
                if planar == ffmpeg::format::sample::Type::Planar {
                    // Planar format - interleave channels
                    for i in 0..nb_samples {
                        for ch in 0..channels.min(target_channels as usize) {
                            let plane = frame.plane::<i16>(ch);
                            if i < plane.len() {
                                output.push(plane[i]);
                            }
                        }
                        // Fill remaining channels with zeros if needed
                        for _ in channels..target_channels as usize {
                            output.push(0);
                        }
                    }
                } else {
                    // Packed format - already interleaved
                    let data = frame.plane::<i16>(0);
                    output.extend_from_slice(&data[..nb_samples * channels]);
                }
            }
            Sample::F32(planar) => {
                // Convert f32 to i16
                if planar == ffmpeg::format::sample::Type::Planar {
                    for i in 0..nb_samples {
                        for ch in 0..channels.min(target_channels as usize) {
                            let plane = frame.plane::<f32>(ch);
                            if i < plane.len() {
                                let sample = (plane[i] * 32767.0).clamp(-32768.0, 32767.0) as i16;
                                output.push(sample);
                            }
                        }
                        for _ in channels..target_channels as usize {
                            output.push(0);
                        }
                    }
                } else {
                    let data = frame.plane::<f32>(0);
                    for sample in &data[..nb_samples * channels] {
                        let s = (*sample * 32767.0).clamp(-32768.0, 32767.0) as i16;
                        output.push(s);
                    }
                }
            }
            _ => {
                // For other formats, try to get as bytes and convert
                debug!("Unsupported audio format: {:?}, returning silence", format);
                output.resize(nb_samples * target_channels as usize, 0);
            }
        }

        output
    }

    /// Decode an Opus packet asynchronously (non-blocking, fire-and-forget)
    /// Decoded samples are sent to the sample_rx channel
    pub fn decode_async(&self, data: &[u8]) {
        let _ = self.cmd_tx.send(AudioCommand::DecodeAsync(data.to_vec()));
    }

    /// Get sample rate
    pub fn sample_rate(&self) -> u32 {
        self.sample_rate
    }

    /// Get channel count
    pub fn channels(&self) -> u32 {
        self.channels
    }
}

impl Drop for AudioDecoder {
    fn drop(&mut self) {
        let _ = self.cmd_tx.send(AudioCommand::Stop);
    }
}

/// Audio player using cpal with optimized lock-free-ish ring buffer
/// Supports sample rate conversion and dynamic device switching
pub struct AudioPlayer {
    /// Input sample rate (from decoder, typically 48000Hz)
    input_sample_rate: u32,
    /// Output sample rate (device native rate)
    output_sample_rate: u32,
    channels: u32,
    buffer: Arc<AudioRingBuffer>,
    stream: Arc<Mutex<Option<cpal::Stream>>>,
    /// Flag to indicate stream needs recreation (device change)
    needs_restart: Arc<AtomicBool>,
    /// Current device name for change detection
    current_device_name: Arc<Mutex<String>>,
    /// Resampler state for 48000 -> device rate conversion
    resampler: Arc<Mutex<AudioResampler>>,
}

/// Simple linear resampler for audio rate conversion
struct AudioResampler {
    input_rate: u32,
    output_rate: u32,
    /// Fractional sample position for interpolation
    phase: f64,
    /// Last sample for interpolation (per channel)
    last_samples: Vec<i16>,
}

/// Lock-free ring buffer for audio samples
/// Uses atomic indices for read/write positions to minimize lock contention
pub struct AudioRingBuffer {
    samples: Mutex<Vec<i16>>,
    read_pos: AtomicUsize,
    write_pos: AtomicUsize,
    capacity: usize,
}

impl AudioRingBuffer {
    fn new(capacity: usize) -> Self {
        Self {
            samples: Mutex::new(vec![0i16; capacity]),
            read_pos: AtomicUsize::new(0),
            write_pos: AtomicUsize::new(0),
            capacity,
        }
    }

    fn available(&self) -> usize {
        let write = self.write_pos.load(Ordering::Acquire);
        let read = self.read_pos.load(Ordering::Acquire);
        if write >= read {
            write - read
        } else {
            self.capacity - read + write
        }
    }

    fn free_space(&self) -> usize {
        self.capacity - 1 - self.available()
    }

    /// Write samples to buffer (called from decoder thread)
    fn write(&self, data: &[i16]) {
        let mut samples = self.samples.lock();
        let mut write_pos = self.write_pos.load(Ordering::Acquire);
        let read_pos = self.read_pos.load(Ordering::Acquire);

        for &sample in data {
            let next_pos = (write_pos + 1) % self.capacity;
            // Don't overwrite unread data
            if next_pos != read_pos {
                samples[write_pos] = sample;
                write_pos = next_pos;
            } else {
                // Buffer full - drop remaining samples
                break;
            }
        }

        self.write_pos.store(write_pos, Ordering::Release);
    }

    /// Read samples from buffer (called from audio callback - must be fast!)
    fn read(&self, out: &mut [i16]) {
        let samples = self.samples.lock();
        let write_pos = self.write_pos.load(Ordering::Acquire);
        let mut read_pos = self.read_pos.load(Ordering::Acquire);

        for sample in out.iter_mut() {
            if read_pos == write_pos {
                *sample = 0; // Underrun - output silence
            } else {
                *sample = samples[read_pos];
                read_pos = (read_pos + 1) % self.capacity;
            }
        }

        self.read_pos.store(read_pos, Ordering::Release);
    }
}

impl AudioResampler {
    fn new(input_rate: u32, output_rate: u32, channels: u32) -> Self {
        Self {
            input_rate,
            output_rate,
            phase: 0.0,
            last_samples: vec![0i16; channels as usize],
        }
    }

    /// Resample audio from input_rate to output_rate using linear interpolation
    /// Returns resampled samples
    fn resample(&mut self, input: &[i16], channels: u32) -> Vec<i16> {
        if self.input_rate == self.output_rate {
            return input.to_vec();
        }

        let ratio = self.input_rate as f64 / self.output_rate as f64;
        let input_frames = input.len() / channels as usize;
        let output_frames = ((input_frames as f64) / ratio).ceil() as usize;
        let mut output = Vec::with_capacity(output_frames * channels as usize);

        let channels = channels as usize;

        for _ in 0..output_frames {
            let input_idx = self.phase as usize;
            let frac = self.phase - input_idx as f64;

            for ch in 0..channels {
                let sample_idx = input_idx * channels + ch;
                let next_idx = (input_idx + 1) * channels + ch;

                let s0 = if sample_idx < input.len() {
                    input[sample_idx]
                } else {
                    self.last_samples.get(ch).copied().unwrap_or(0)
                };

                let s1 = if next_idx < input.len() {
                    input[next_idx]
                } else if sample_idx < input.len() {
                    input[sample_idx]
                } else {
                    s0
                };

                // Linear interpolation
                let interpolated = s0 as f64 + (s1 as f64 - s0 as f64) * frac;
                output.push(interpolated.clamp(-32768.0, 32767.0) as i16);
            }

            self.phase += ratio;
        }

        // Keep fractional phase, reset integer part
        self.phase = self.phase.fract();

        // Store last samples for next buffer's interpolation
        if input.len() >= channels {
            for ch in 0..channels {
                let idx = input.len() - channels + ch;
                self.last_samples[ch] = input[idx];
            }
        }

        output
    }

    /// Update rates (for device change)
    fn set_output_rate(&mut self, output_rate: u32) {
        if self.output_rate != output_rate {
            self.output_rate = output_rate;
            self.phase = 0.0;
            info!("Resampler updated: {}Hz -> {}Hz", self.input_rate, output_rate);
        }
    }
}

impl AudioPlayer {
    /// Create a new audio player
    pub fn new(sample_rate: u32, channels: u32) -> Result<Self> {
        use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};
        use cpal::SampleFormat;

        info!("Creating audio player: {}Hz, {} channels", sample_rate, channels);

        let host = cpal::default_host();

        let device = host.default_output_device()
            .context("No audio output device found")?;

        info!("Using audio device: {}", device.name().unwrap_or_default());

        // Query supported configurations
        let supported_configs: Vec<_> = device.supported_output_configs()
            .map(|configs| configs.collect())
            .unwrap_or_default();

        if supported_configs.is_empty() {
            return Err(anyhow!("No supported audio configurations found"));
        }

        // Log available configurations for debugging
        for cfg in &supported_configs {
            debug!("Supported config: {:?} channels, {:?}-{:?} Hz, format {:?}",
                cfg.channels(), cfg.min_sample_rate().0, cfg.max_sample_rate().0, cfg.sample_format());
        }

        // Find best matching configuration
        // Prefer: f32 format (most compatible), matching channels, matching sample rate
        let target_rate = cpal::SampleRate(sample_rate);
        let target_channels = channels as u16;

        // Try to find a config that supports our sample rate and channel count
        let mut best_config = None;
        let mut best_score = 0i32;

        for cfg in &supported_configs {
            let mut score = 0i32;

            // Prefer f32 format (most widely supported)
            if cfg.sample_format() == SampleFormat::F32 {
                score += 100;
            } else if cfg.sample_format() == SampleFormat::I16 {
                score += 50;
            }

            // Prefer matching channel count
            if cfg.channels() == target_channels {
                score += 50;
            } else if cfg.channels() >= target_channels {
                score += 25;
            }

            // Check if sample rate is in range
            if target_rate >= cfg.min_sample_rate() && target_rate <= cfg.max_sample_rate() {
                score += 100;
            } else if cfg.max_sample_rate().0 >= 44100 {
                score += 25; // At least supports reasonable rates
            }

            if score > best_score {
                best_score = score;
                best_config = Some(cfg.clone());
            }
        }

        let supported_range = best_config
            .ok_or_else(|| anyhow!("No suitable audio configuration found"))?;

        // Determine actual sample rate to use
        let actual_rate = if target_rate >= supported_range.min_sample_rate()
            && target_rate <= supported_range.max_sample_rate() {
            target_rate
        } else if cpal::SampleRate(48000) >= supported_range.min_sample_rate()
            && cpal::SampleRate(48000) <= supported_range.max_sample_rate() {
            cpal::SampleRate(48000)
        } else if cpal::SampleRate(44100) >= supported_range.min_sample_rate()
            && cpal::SampleRate(44100) <= supported_range.max_sample_rate() {
            cpal::SampleRate(44100)
        } else {
            supported_range.max_sample_rate()
        };

        let actual_channels = supported_range.channels();
        let sample_format = supported_range.sample_format();

        info!("Using audio config: {}Hz, {} channels, format {:?}",
            actual_rate.0, actual_channels, sample_format);

        // Buffer for ~150ms of audio (handles network jitter)
        // 48000Hz * 2ch * 0.15s = 14400 samples
        // Larger buffer prevents underruns from network jitter
        let buffer_size = (actual_rate.0 as usize) * (actual_channels as usize) * 150 / 1000;
        let buffer = Arc::new(AudioRingBuffer::new(buffer_size));

        info!("Audio buffer size: {} samples (~{}ms)", buffer_size,
            buffer_size * 1000 / (actual_rate.0 as usize * actual_channels as usize));

        let config = supported_range.with_sample_rate(actual_rate).into();

        let buffer_clone = buffer.clone();

        // Build stream based on sample format
        // The callback reads from the ring buffer - optimized for low latency
        let stream = match sample_format {
            SampleFormat::F32 => {
                let buffer_f32 = buffer_clone.clone();
                device.build_output_stream(
                    &config,
                    move |data: &mut [f32], _| {
                        // Read i16 samples in bulk and convert to f32
                        let mut i16_buf = vec![0i16; data.len()];
                        buffer_f32.read(&mut i16_buf);
                        for (out, &sample) in data.iter_mut().zip(i16_buf.iter()) {
                            *out = sample as f32 / 32768.0;
                        }
                    },
                    |err| {
                        error!("Audio stream error: {}", err);
                    },
                    None,
                ).context("Failed to create f32 audio stream")?
            }
            SampleFormat::I16 => {
                let buffer_i16 = buffer_clone.clone();
                device.build_output_stream(
                    &config,
                    move |data: &mut [i16], _| {
                        buffer_i16.read(data);
                    },
                    |err| {
                        error!("Audio stream error: {}", err);
                    },
                    None,
                ).context("Failed to create i16 audio stream")?
            }
            _ => {
                // Fallback: try f32 anyway
                let buffer_fallback = buffer_clone.clone();
                device.build_output_stream(
                    &config,
                    move |data: &mut [f32], _| {
                        let mut i16_buf = vec![0i16; data.len()];
                        buffer_fallback.read(&mut i16_buf);
                        for (out, &sample) in data.iter_mut().zip(i16_buf.iter()) {
                            *out = sample as f32 / 32768.0;
                        }
                    },
                    |err| {
                        error!("Audio stream error: {}", err);
                    },
                    None,
                ).context("Failed to create audio stream with fallback format")?
            }
        };

        stream.play().context("Failed to start audio playback")?;

        let device_name = device.name().unwrap_or_default();
        info!("Audio player started successfully on '{}'", device_name);

        // Create resampler for input_rate -> output_rate conversion
        let resampler = AudioResampler::new(sample_rate, actual_rate.0, actual_channels as u32);

        if sample_rate != actual_rate.0 {
            info!("Audio resampling enabled: {}Hz -> {}Hz", sample_rate, actual_rate.0);
        }

        Ok(Self {
            input_sample_rate: sample_rate,
            output_sample_rate: actual_rate.0,
            channels: actual_channels as u32,
            buffer,
            stream: Arc::new(Mutex::new(Some(stream))),
            needs_restart: Arc::new(AtomicBool::new(false)),
            current_device_name: Arc::new(Mutex::new(device_name)),
            resampler: Arc::new(Mutex::new(resampler)),
        })
    }

    /// Push audio samples to the player (with automatic resampling)
    pub fn push_samples(&self, samples: &[i16]) {
        // Check if device changed and we need to restart
        self.check_device_change();

        // Resample if needed (48000Hz decoder -> device rate)
        let resampled = {
            let mut resampler = self.resampler.lock();
            resampler.resample(samples, self.channels)
        };

        self.buffer.write(&resampled);
    }

    /// Get buffer fill level
    pub fn buffer_available(&self) -> usize {
        self.buffer.available()
    }

    /// Get output sample rate (device rate)
    pub fn sample_rate(&self) -> u32 {
        self.output_sample_rate
    }

    /// Get channel count
    pub fn channels(&self) -> u32 {
        self.channels
    }

    /// Check if the default audio device changed and restart stream if needed
    fn check_device_change(&self) {
        use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};

        let host = cpal::default_host();
        let current_device = match host.default_output_device() {
            Some(d) => d,
            None => return,
        };

        let new_name = current_device.name().unwrap_or_default();
        let current_name = self.current_device_name.lock().clone();

        if new_name != current_name && !new_name.is_empty() {
            warn!("Audio device changed: '{}' -> '{}'", current_name, new_name);

            // Update device name
            *self.current_device_name.lock() = new_name.clone();

            // Recreate the audio stream on the new device
            if let Err(e) = self.recreate_stream(&current_device) {
                error!("Failed to switch audio device: {}", e);
            } else {
                info!("Audio switched to '{}'", new_name);
            }
        }
    }

    /// Recreate the audio stream on a new device
    fn recreate_stream(&self, device: &cpal::Device) -> Result<()> {
        use cpal::traits::{DeviceTrait, StreamTrait};
        use cpal::SampleFormat;

        // Stop old stream
        *self.stream.lock() = None;

        // Query supported configurations
        let supported_configs: Vec<_> = device.supported_output_configs()
            .map(|configs| configs.collect())
            .unwrap_or_default();

        if supported_configs.is_empty() {
            return Err(anyhow!("No supported audio configurations on new device"));
        }

        // Find best config (prefer F32, matching channels)
        let target_channels = self.channels as u16;
        let mut best_config = None;
        let mut best_score = 0i32;

        for cfg in &supported_configs {
            let mut score = 0i32;
            if cfg.sample_format() == SampleFormat::F32 { score += 100; }
            if cfg.channels() == target_channels { score += 50; }
            if cfg.max_sample_rate().0 >= 44100 { score += 25; }

            if score > best_score {
                best_score = score;
                best_config = Some(cfg.clone());
            }
        }

        let supported_range = best_config
            .ok_or_else(|| anyhow!("No suitable audio config on new device"))?;

        // Pick sample rate
        let actual_rate = if cpal::SampleRate(48000) >= supported_range.min_sample_rate()
            && cpal::SampleRate(48000) <= supported_range.max_sample_rate() {
            cpal::SampleRate(48000)
        } else if cpal::SampleRate(44100) >= supported_range.min_sample_rate()
            && cpal::SampleRate(44100) <= supported_range.max_sample_rate() {
            cpal::SampleRate(44100)
        } else {
            supported_range.max_sample_rate()
        };

        let sample_format = supported_range.sample_format();
        let config = supported_range.with_sample_rate(actual_rate).into();
        let buffer = self.buffer.clone();

        info!("New device config: {}Hz, {} channels, {:?}",
            actual_rate.0, self.channels, sample_format);

        // Update resampler for new output rate
        self.resampler.lock().set_output_rate(actual_rate.0);

        // Build new stream
        let stream = match sample_format {
            SampleFormat::F32 => {
                let buf = buffer.clone();
                device.build_output_stream(
                    &config,
                    move |data: &mut [f32], _| {
                        let mut i16_buf = vec![0i16; data.len()];
                        buf.read(&mut i16_buf);
                        for (out, &sample) in data.iter_mut().zip(i16_buf.iter()) {
                            *out = sample as f32 / 32768.0;
                        }
                    },
                    |err| error!("Audio stream error: {}", err),
                    None,
                ).context("Failed to create audio stream")?
            }
            SampleFormat::I16 => {
                let buf = buffer.clone();
                device.build_output_stream(
                    &config,
                    move |data: &mut [i16], _| {
                        buf.read(data);
                    },
                    |err| error!("Audio stream error: {}", err),
                    None,
                ).context("Failed to create audio stream")?
            }
            _ => {
                let buf = buffer.clone();
                device.build_output_stream(
                    &config,
                    move |data: &mut [f32], _| {
                        let mut i16_buf = vec![0i16; data.len()];
                        buf.read(&mut i16_buf);
                        for (out, &sample) in data.iter_mut().zip(i16_buf.iter()) {
                            *out = sample as f32 / 32768.0;
                        }
                    },
                    |err| error!("Audio stream error: {}", err),
                    None,
                ).context("Failed to create audio stream")?
            }
        };

        stream.play().context("Failed to start audio on new device")?;
        *self.stream.lock() = Some(stream);

        Ok(())
    }
}
